{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8362adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, sum, count, split\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from kafka import KafkaProducer, KafkaAdminClient\n",
    "from kafka.admin import NewTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd32bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/08 23:08:04 WARN Utils: Your hostname, hasirama resolves to a loopback address: 127.0.1.1; using 192.168.0.219 instead (on interface enp7s0)\n",
      "22/12/08 23:08:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/08 23:08:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "conf.setAll([\n",
    "    ('spark.master', 'local'),\n",
    "    ('spark.app.name', 'Kafka ETL'),\n",
    "    ('spark.submit.deployment', 'client'),\n",
    "    ('spark.ui.showConsoleProgress', 'true'),\n",
    "    ('spark.eventLog.enabled', 'false'),\n",
    "    ('spark.logConf', 'false'),\n",
    "    ('spark.driver.host', 'localhost'),\n",
    "    ('spark.driver.memory', '6g'),\n",
    "])\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40038fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system('spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 consume.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506a6030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----------+--------------------+--------------------+--------------------+\n",
      "|             authors| category|      date|            headline|                link|   short_description|\n",
      "+--------------------+---------+----------+--------------------+--------------------+--------------------+\n",
      "|Carla K. Johnson, AP|U.S. NEWS|2022-09-23|Over 4 Million Am...|https://www.huffp...|Health experts sa...|\n",
      "|      Mary Papenfuss|U.S. NEWS|2022-09-23|American Airlines...|https://www.huffp...|He was subdued by...|\n",
      "|       Elyse Wanshel|   COMEDY|2022-09-23|23 Of The Funnies...|https://www.huffp...|\"Until you have a...|\n",
      "|    Caroline Bologna|PARENTING|2022-09-23|The Funniest Twee...|https://www.huffp...|\"Accidentally put...|\n",
      "|      Nina Golgowski|U.S. NEWS|2022-09-22|Woman Who Called ...|https://www.huffp...|Amy Cooper accuse...|\n",
      "+--------------------+---------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdf = spark.read.options(inferSchema=True,header=True).json('News_Category_Dataset_v3.json')\n",
    "rdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c102844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+----------+-----------+\n",
      "|             authors| category|   short_description|word_count|num_authors|\n",
      "+--------------------+---------+--------------------+----------+-----------+\n",
      "|Carla K. Johnson, AP|U.S. NEWS|Health experts sa...|        29|          1|\n",
      "|      Mary Papenfuss|U.S. NEWS|He was subdued by...|        28|          1|\n",
      "|       Elyse Wanshel|   COMEDY|\"Until you have a...|        12|          1|\n",
      "|    Caroline Bologna|PARENTING|\"Accidentally put...|        25|          1|\n",
      "|      Nina Golgowski|U.S. NEWS|Amy Cooper accuse...|        25|          1|\n",
      "+--------------------+---------+--------------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_word_count(x):\n",
    "    \n",
    "    return len(x.split(' '))\n",
    "\n",
    "def get_author_count(x):\n",
    "    \n",
    "    return len(x.split('and'))\n",
    "\n",
    "rdf = rdf.drop('date', 'headline', 'link')\n",
    "countUDF = udf(lambda x: get_word_count(x), IntegerType())\n",
    "rdf = rdf.withColumn('word_count', countUDF(rdf.short_description))\n",
    "authorCountUDF = udf(lambda x: get_author_count(x), IntegerType())\n",
    "rdf = rdf.withColumn('num_authors', authorCountUDF(rdf.authors))\n",
    "rdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290bab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+----------+\n",
      "|    category|num_authors|word_count|\n",
      "+------------+-----------+----------+\n",
      "|      SPORTS|       5540|     70136|\n",
      "|       MEDIA|       3135|     42646|\n",
      "|BLACK VOICES|       5102|     78712|\n",
      "|    POLITICS|      41931|    573293|\n",
      "|        ARTS|       1857|     33039|\n",
      "+------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "group = rdf.groupBy('category').agg(\n",
    "    sum('num_authors').alias('num_authors'),\n",
    "    sum('word_count').alias('word_count'),\n",
    ")\n",
    "group.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf046cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a447f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = KafkaAdminClient(\n",
    "    bootstrap_servers=['127.0.0.1:9092'],\n",
    "    client_id='kafka-spark-etl',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ec1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = []\n",
    "topic = NewTopic(\n",
    "    name='spark-kafka-etl',\n",
    "    num_partitions=2,\n",
    "    replication_factor=2,\n",
    ")\n",
    "topic_list.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "648bd28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(data):\n",
    "    return json.dumps(data).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b4da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition(key, all, available):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f65f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_producer():\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=['127.0.0.1:9092'],\n",
    "        value_serializer=serialize,\n",
    "        partitioner=get_partition,\n",
    "    )\n",
    "    \n",
    "    return producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91e929a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = get_producer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22a349a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "rows = group.collect()\n",
    "print(len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "146a57fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    data = {}\n",
    "    data['category'] = row.category\n",
    "    data['num_author'] = row.num_authors\n",
    "    data['word_count'] = row.word_count\n",
    "    producer.send(topic=topic.name, value=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a926875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark-kafka-etl'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abd8ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45459d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kafka-metrics-count': {'count': 56.0},\n",
       " 'producer-metrics': {'connection-close-rate': 0.03332335286982692,\n",
       "  'connection-creation-rate': 0.0662928865693428,\n",
       "  'select-rate': 0.26607828892431906,\n",
       "  'io-wait-time-ns-avg': 7648676.633834839,\n",
       "  'io-wait-ratio': 0.0020351463285516232,\n",
       "  'io-time-ns-avg': 151664.01863098145,\n",
       "  'io-ratio': 4.035481026369422e-05,\n",
       "  'connection-count': 1.0,\n",
       "  'network-io-rate': 0.26517179090705795,\n",
       "  'outgoing-byte-rate': 112.46597216666004,\n",
       "  'request-rate': 0.13258586541126582,\n",
       "  'request-size-avg': 848.25,\n",
       "  'request-size-max': 3274.0,\n",
       "  'incoming-byte-rate': 108.45119065705963,\n",
       "  'response-rate': 0.13302812645245782,\n",
       "  'request-latency-avg': 26.04728937149048,\n",
       "  'request-latency-max': 100.50106048583984,\n",
       "  'bufferpool-wait-ratio': 0.0,\n",
       "  'batch-size-avg': 3196.0,\n",
       "  'batch-size-max': 3196.0,\n",
       "  'compression-rate-avg': 1.0,\n",
       "  'record-queue-time-avg': 0.001863718032836914,\n",
       "  'record-queue-time-max': 0.001863718032836914,\n",
       "  'produce-throttle-time-avg': 0.0,\n",
       "  'produce-throttle-time-max': 0.0,\n",
       "  'record-send-rate': 1.399621528123889,\n",
       "  'records-per-request-avg': 42.0,\n",
       "  'byte-rate': 106.50453429231014,\n",
       "  'record-retry-rate': 0.0,\n",
       "  'record-error-rate': 0.0,\n",
       "  'record-size-max': 82.0,\n",
       "  'record-size-avg': 82.0,\n",
       "  'requests-in-flight': 0.0,\n",
       "  'metadata-age': 0.065536376953125},\n",
       " 'producer-node-metrics.node-bootstrap-0': {'outgoing-byte-rate': 3.9444270381545934,\n",
       "  'request-rate': 0.0994393266352056,\n",
       "  'request-size-avg': 39.666666666666664,\n",
       "  'request-size-max': 41.0,\n",
       "  'incoming-byte-rate': 106.22290118710407,\n",
       "  'response-rate': 0.09977103165309054,\n",
       "  'request-latency-avg': 34.39640998840332,\n",
       "  'request-latency-max': 100.50106048583984},\n",
       " 'producer-node-metrics.node-0': {'outgoing-byte-rate': 109.10434095015425,\n",
       "  'request-rate': 0.03332447392647925,\n",
       "  'request-size-avg': 3274.0,\n",
       "  'request-size-max': 3274.0,\n",
       "  'incoming-byte-rate': 2.2328037329296877,\n",
       "  'response-rate': 0.03332542559603248,\n",
       "  'request-latency-avg': 0.9999275207519531,\n",
       "  'request-latency-max': 0.9999275207519531},\n",
       " 'producer-topic-metrics.spark-kafka-etl': {'record-send-rate': 1.3996179070450054,\n",
       "  'byte-rate': 106.50426827691733,\n",
       "  'compression-rate': 1.0,\n",
       "  'record-retry-rate': 0.0,\n",
       "  'record-error-rate': 0.0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "producer.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120aaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
